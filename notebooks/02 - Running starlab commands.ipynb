{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tools in `starlab` are designed to be executed from the command line, and chained together to form simulation pipelines. This notebook walks through the process of executing some `starlab` commands up to and including the type of pipelines needed to run full simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ipython, when you put an ! at the beginning of a cell, the cell's contents get passed to the underlying operating system.  This makes it possible to run starlab commands from within ipython.  For example, we can make a King model with 10 stars and $W_0=1.2$ by issuing the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!makeking -n 10 -w 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The down side (there's always a down side, right?) is that this is unwieldy, and we can't easily deal with the output. (We can get at it, just not very *easily*).\n",
    "\n",
    "A better way to deal with this is to use python's `subprocess` module. This allows us to specify input and output of commands, among other things.  We import it as we have imported other modules in the past, and since I'm going to be using both `subprocess.Popen` and `subprocess.PIPE` quite a bit, and don't want to keep typing `subprocess` all the time, I'll import those two things individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from subprocess import Popen, PIPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute the same command as before (to generate a King model) I use `Popen`, thus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "king = Popen([\"makeking\",\"-n\", \"5\", \"-w\",\"5\"], stdout=PIPE, stderr=PIPE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice there's no output (yet). This isn't just  because I've stored the results of the `Popen` call in a variable called king; it's also because even though the command has been built, it hasn't actually run yet. I'll get to that in a minute. Before we get to that, though, there are two more points I want to draw your attention to.\n",
    "\n",
    "First, the command name and its arguments are elements of a list.  Python lists are comma separated collections of objects residing between square brackets.\n",
    "\n",
    "The second thing I want to point out is the last two arguments of the `Popen` call. The two objects `stdout` and `stderr` are output streams for the `makeking` program. They stand for *standard output* and *standard error* respectively. In this case, `makeking` and the other programs that make up starlab send the current collection of stars being simulated to `stdout`, and logging information to `stderr`.  We'll exploit this to get data into and out of the starlab programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = king.communicate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stdout is contained in the first element of `results`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very readable. Part of the problem is that the subprocess module returns strings as byte sequences, rather than unicode, but python 3 maintains a distinction between the two. We can overcome this problem by decoding the byte string and printing the resulting unicode string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(results[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look closely at this, we can see that it contains some overall information about the distribution, and then the bulk of the output is devoted to giving masses, positions, and velocities for each of the stars. That's what we'll have to parse to do the plotting.\n",
    "\n",
    "The other part of `results` is stderr; it contains other information about running the command. We can think of this as metadata, and it really ought to be stored with the rest of our results so that we have a record of what starlab thought at the time the data was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(results[1].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the examples on the starlab website chain together a longish sequence of commands. For example, you often want to make a spatial distribution, then apply a mass function to it, then do some scaling, and add some binaries, and then integrate the whole thing, or generate statistics.  We can do that pretty easily using the framework I've outlined above. \n",
    "\n",
    "We start by creating a list of commands. Recall that each command is itself a list containing the command name and all of its arguments.  So we end up with a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmds = []\n",
    "\n",
    "cmds.append([\"makeking\", \"-n\", \"500\", \"-w\", \"5\", \"-i\",  \"-u\"])\n",
    "cmds.append([\"makemass\", \"-f\", \"2\", \"-l\", \"0.1,\", \"-u\", \"20\"])\n",
    "cmds.append([\"makesecondary\", \"-f\", \"0.1\", \"-l\", \"0.25\"])\n",
    "cmds.append([\"scale\", \"-m\", \"1\", \"-e\", \"-0.25\", \"-q\", \"0.5\"]) \n",
    "cmds.append([\"makebinary\", \"-l\", \"1\", \"-u\", \"10\"])\n",
    "cmds.append([\"sys_stats\", \"-n\"])\n",
    "\n",
    "print(cmds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Popen` command wouldn't know what to do with this list of lists, so we have to make a process for each piece. We want the output of each command to be the input for the next command (i.e., we apply `makemass` to the output of `makeking` in this example); we do this by connecting the `stdin` of each process to the `stdout` of the previous process.  We tell `Popen` that we're going to want to do this by using the special handle `PIPE`, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "procs = []\n",
    "for index, cmd in enumerate(cmds):\n",
    "    print(index, cmd)\n",
    "    if index > 0:\n",
    "        procs.append(Popen(cmd, stdout=PIPE, stderr=PIPE, stdin=procs[index-1].stdout))\n",
    "    else:\n",
    "        procs.append(Popen(cmd, stdout=PIPE, stderr=PIPE))\n",
    "    inp = procs[-1].stdout\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `if` statement here just reflects the fact that our first command doesn't have any input, so we don't want to try to connect it to anything.  We get the output of the whole chain of commands by telling the last one to communicate.  It then requests its input from previous commands, and they're required to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = procs[-1].communicate()\n",
    "print(\"---------------- stdout ------------------\")\n",
    "print(result[0].decode('utf-8'))\n",
    "print(\"---------------- stderr ------------------\")\n",
    "print(result[1].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this case, `stdout` gives us nothing, while `sdterr` gives the statistics we asked for. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same thing again, but instead of asking for statistics, we run kira to evolve the star cluster in time. **Don't be surprised if this takes a while, and produces lots of output!** We'll deal with the second of these issues shortly. Sadly, the time issue is not something we can easily overcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmds = []\n",
    "\n",
    "cmds.append([\"makeking\", \"-n\", \"500\", \"-w\", \"5\", \"-i\",  \"-u\"])\n",
    "cmds.append([\"makemass\", \"-f\", \"2\", \"-l\", \"0.1,\", \"-u\", \"20\"])\n",
    "cmds.append([\"makesecondary\", \"-f\", \"0.1\", \"-l\", \"0.25\"])\n",
    "cmds.append([\"makebinary\", \"-l\", \"1\", \"-u\", \"10\"])\n",
    "cmds.append([\"scale\", \"-m\", \"1\", \"-e\", \"-0.25\", \"-q\", \"0.5\"]) \n",
    "cmds.append([\"kira\", \"-t\", \"100\", \"-d\", \"1\", \"-D\", \"10\", \"-f\", \"0.3\", \"-n\", \"10\", \"-q\", \"0.5\", \"-G\", \"2\", \"-B\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "procs = []\n",
    "for index, cmd in enumerate(cmds):\n",
    "    print(index, cmd)\n",
    "    if index > 0:\n",
    "        procs.append(Popen(cmd, stdout=PIPE, stderr=PIPE, stdin=procs[index-1].stdout))\n",
    "    else:\n",
    "        procs.append(Popen(cmd, stdout=PIPE, stderr=PIPE))\n",
    "    inp = procs[-1].stdout\n",
    "    \n",
    "result = procs[-1].communicate()\n",
    "print(\"---------------- stdout ------------------\")\n",
    "print(result[0].decode('utf-8'))\n",
    "print(\"---------------- stderr ------------------\")\n",
    "print(result[1].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having typed the preceding block of code twice now, I'm sure I'm going to use it again (\"Everything that happens once can never happen again. But everything that happens twice will surely happen a third time\" -- Arab Proverb, according to Paulo Coelho) so I'll make a function out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_commands(cmds):\n",
    "    procs = []\n",
    "    for index, cmd in enumerate(cmds):\n",
    "        if index > 0:\n",
    "            procs.append(Popen(cmd, stdout=PIPE, stderr=PIPE, stdin=procs[index-1].stdout))\n",
    "        else:\n",
    "            procs.append(Popen(cmd, stdout=PIPE, stderr=PIPE))\n",
    "        inp = procs[-1].stdout\n",
    "    \n",
    "    result = procs[-1].communicate()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have left off the print statements since generally I want to do something with the result other than look at it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can generate some results, we'd like to be able to do something meaningful with them. The first thing we want to do is to plot a snapshot of the star field at a moment in time. To get to that point, we need to be able to transform the nearly human readable output format that comes from e.g. `makeking` or `makeplummer` into a list of positions, velocities, masses, and so on.\n",
    "\n",
    "Starlab output is organized into \"Stories\".  Stories can consist of definitions, lines of text, and other stories.  In my mind, this maps reasonably well onto a python class, so that's what I'm going to do with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class Story:\n",
    "    \"\"\"A starlab story object.\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Create the (empty) data structures we will need.\"\"\"\n",
    "        self.story_lines = []\n",
    "        self.story_vals = dict()\n",
    "        self.story_subobjects = []\n",
    "        self.kind = None\n",
    "        return\n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"A readable representation of the story object.\"\"\"\n",
    "        return \"%s, %d lines, %d values, %d subobjects\" % (self.kind, len(self.story_lines), len(self.story_vals.keys()), len(self.story_subobjects))\n",
    "\n",
    "    def process_line(self, line):\n",
    "        \"\"\"Deal with lines that hold a single value\"\"\"\n",
    "        # if we can tokenize into an equality, store in the dict, otherwise as a line.\n",
    "        chunks = re.split('=', line)\n",
    "#        print chunks, len(chunks)\n",
    "        if len(chunks) == 2:\n",
    "            self.story_vals[chunks[0].strip()] = chunks[1].strip()\n",
    "        else:\n",
    "            self.story_lines.append(line)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stories begin with a line that looks like\n",
    "\n",
    "`(Storyname`\n",
    "\n",
    "and end with a line that looks like\n",
    "\n",
    "`)Storyname`\n",
    "\n",
    "To turn output lines into stories, we look at each line. When we see a line that starts a story, we launch in to \"story parsing mode\" and build a new story from that point until we hit the end of the story.  That action is taken care of in the `parse_lines` function below. The `parse_output` function is mostly just a wrapper so that the top level output can generate the right `parse_lines` call to begin with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_output(results):\n",
    "    \"\"\"Move through a set of output from a starlab program, building a list of stories.\"\"\"\n",
    "    stories = []\n",
    "    lines = re.split(\"\\n\", results)\n",
    "\n",
    "    nextidx = -1\n",
    "    \n",
    "    for index, line in enumerate(lines):\n",
    "        if index >= nextidx:\n",
    "            storystart = re.match(\"^\\((\\w+)\",line)\n",
    "            if storystart:\n",
    "                #print \"in parse_output, calling parse_lines:\", index, storystart.group(1)\n",
    "                nextidx, newstory = parse_lines(lines, index+1, storystart.group(1))\n",
    "                #print \"in parse_output, back from parse_lines:\", nextidx, str(newstory)\n",
    "                stories.append(newstory)\n",
    "    return stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_lines(lines, startidx, name):\n",
    "    \"\"\"Recursively define stories from lines of output.\"\"\"\n",
    "    thestory = Story()\n",
    "    thestory.kind = name\n",
    "    nextidx = -1\n",
    "    for index,line in enumerate(lines[startidx:]):\n",
    "        if index >= nextidx-startidx:\n",
    "            #print \"%s Line is %s\"%(name, line)\n",
    "            storystart = re.match(\"^\\((\\w+)\",line)\n",
    "            storyend = re.match(\"\\)%s\"%name, line)\n",
    "            if storyend: # we've hit the end of our story; get out and pass it back up\n",
    "                endindex = index\n",
    "                break\n",
    "            elif storystart: # new story; start up a new parse_lines\n",
    "                #print \"in parse_lines, calling parse_lines:\", startidx+index+1, storystart.group(1)\n",
    "                nextidx, newstory = parse_lines(lines, startidx+index + 1, storystart.group(1))\n",
    "                #print \"back\", nextidx, str(newstory)\n",
    "                thestory.story_subobjects.append(newstory)\n",
    "            else:\n",
    "                thestory.process_line(line)\n",
    "    return endindex+startidx+1, thestory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if it works. Generate a king model with 5 stars, and check the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmds = []\n",
    "cmds.append([\"makeking\", \"-n\", \"5\", \"-w\", \"5\", \"-i\",  \"-u\"])\n",
    "result = process_commands(cmds)\n",
    "slist = parse_output(result[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many stories do we get in our list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(slist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, what is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(slist[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have a `Particle`, with 0 lines, 1 value, and 9 subobjects.  This `Particle` represents the cluster as a whole.  Let's look at the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(slist[0].story_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the overall number of sub-particles.  What about the subobjects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for obj in slist[0].story_subobjects:\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Log`, `Dynamics`, `Hydro` and `Star` stories are substories of all `Particles`.  We additionally have `Particle` stories for the 5 particles in the cluster.  The values in the `Dynamics` and `Star` stories might be useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(slist[0].story_subobjects[1])\n",
    "print(slist[0].story_subobjects[1].story_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(slist[0].story_subobjects[3])\n",
    "print(slist[0].story_subobjects[3].story_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For plotting, we're only going to need the information stored in the `Dynamics` substory of each `Particle` substory.  These two functions extract that information and then make a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_particle_dynamics(story):\n",
    "    \"\"\" recursively extract dynamics objects to get masses, positions, and velocities.\n",
    "\n",
    "    Quick and dirty.\"\"\"\n",
    "    particles = []\n",
    "    if story.kind == \"Dynamics\":\n",
    "        x, y, z = story.story_vals['r'].split(\" \")\n",
    "        vx, vy, vz = story.story_vals['v'].split(\" \")\n",
    "        m = story.story_vals['m']\n",
    "        particles.append( (float(x), float(y), float(z), float(vx), float(vy), float(vz), float(m)) )\n",
    "        #print \"appending: \", particles[-1]\n",
    "    elif len(story.story_subobjects) > 0:\n",
    "        for obj in story.story_subobjects:\n",
    "            particles.extend(extract_particle_dynamics(obj))\n",
    "\n",
    "    return particles\n",
    "\n",
    "def vis_story_3d(story_list):\n",
    "    xvals = []\n",
    "    yvals = []\n",
    "    zvals = []\n",
    "    vxs = []\n",
    "    vys = []\n",
    "    vzs = []\n",
    "    masses = []\n",
    "    \n",
    "    # the way this is currently set up, we only keep the particle list from the last story\n",
    "    for story in story_list:\n",
    "        partlist = extract_particle_dynamics(story)\n",
    "        \n",
    "    for particle in partlist:\n",
    "        xvals.append(particle[0])\n",
    "        yvals.append(particle[1])\n",
    "        zvals.append(particle[2])\n",
    "        vxs.append(particle[3])\n",
    "        vys.append(particle[4])\n",
    "        vzs.append(particle[5])\n",
    "        masses.append(particle[6])\n",
    "        \n",
    "    # now do the plot\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.gca(projection='3d')\n",
    "    # not super happy with the colors yet.\n",
    "    ax.scatter(np.array(xvals), np.array(yvals), np.array(zvals), c=np.array(masses))\n",
    "    #ax.plot(np.array(xvals), np.array(yvals), np.array(zvals), \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can try it out, we need to make sure matplotlib is loaded, and ready to work in three dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vis_story_3d(slist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not enough stars. It's boring. Let's do some more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "barking = Popen([\"makeking\",\"-n\", \"2000\", \"-w\",\"5\"], stdout=PIPE, stderr=PIPE) \n",
    "results = barking.communicate()\n",
    "slist = parse_output(results[0].decode('utf-8'))\n",
    "vis_story_3d(slist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot that just fine (though it turns out if we want to evolve 2000 stars for any length of time, we're going to be waiting a long while). Let's dial it back a bit to make something we can run reasonably quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmds = []\n",
    "cmds.append([\"makeking\", \"-n\", \"500\", \"-w\", \"5\", \"-i\",  \"-u\"])\n",
    "cmds.append([\"makemass\", \"-f\", \"2\", \"-l\", \"0.1,\", \"-u\", \"20\"])\n",
    "result = process_commands(cmds)\n",
    "slist = parse_output(result[0].decode('utf-8'))\n",
    "vis_story_3d(slist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not as dense, but still enough to be interesting. Let's run it forward in time for a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmds = []\n",
    "cmds.append([\"makeking\", \"-n\", \"500\", \"-w\", \"5\", \"-i\",  \"-u\"])\n",
    "cmds.append([\"makemass\", \"-f\", \"2\", \"-l\", \"0.1,\", \"-u\", \"20\"])\n",
    "cmds.append([\"kira\", \"-t\", \"10\", \"-d\", \"1\", \"-D\", \"2\", \"-f\", \"0.3\", \"-n\", \"10\", \"-q\", \"0.5\", \"-G\", \"2\", \"-B\"])\n",
    "result = process_commands(cmds)\n",
    "slist = parse_output(result[0].decode('utf-8'))\n",
    "vis_story_3d(slist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Notice that running forward in time makes the stars a lot less densely packed. This is because individual stars have collisions that knock them out of the cluster. How many are left?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(slist[4].story_subobjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Interesting. If I want to study this in a more systematic way, I'm going to want to wrap the process in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def premain(startn):\n",
    "    \"\"\"Run a plummer model for 10 dynamical times and return the number of stars remaining.\"\"\"\n",
    "    from subprocess import Popen, PIPE\n",
    "    #from starlab import parse_output, extract_particle_dynamics\n",
    "    \n",
    "    print(\"running %d particles\" % startn)\n",
    "    cmds = []\n",
    "\n",
    "    cmds.append([\"makeplummer\", \"-n\", \"%d\"%startn, \"-i\"])\n",
    "    cmds.append([\"kira\", \"-t\", \"10\", \"-d\", \"1\", \"-D\", \"2\", \"-n\", \"10\", \"-q\", \"0.5\", \"-G\", \"2\"])\n",
    "    procs = []\n",
    "    for index, cmd in enumerate(cmds):\n",
    "        print(index, cmd)\n",
    "        if index > 0:\n",
    "            procs.append(Popen(cmd, stdout=PIPE, stderr=PIPE, stdin=procs[index-1].stdout))\n",
    "        else:\n",
    "            procs.append(Popen(cmd, stdout=PIPE, stderr=PIPE))\n",
    "    inp = procs[-1].stdout\n",
    "    \n",
    "    result = procs[-1].communicate()\n",
    "    slist = parse_output(result[0].decode('utf-8'))\n",
    "    return len(extract_particle_dynamics(slist[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "premain(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "premain(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Because the populations of stars are randomly drawn from distributions, each run will be slightly different. We can do some interesting statistical analysis here if we generate enough data, but to do that we're going to want to run in parallel, and that's the topic for another notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
